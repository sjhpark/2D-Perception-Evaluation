# Evaluation of Mask R-CNN Inferences
Computation of Confusion Matrix and Performance Metrics for Instance Segmentations Generated by Mask R-CNN

---

# Installation & Inference Guide
## Setup
```bash
conda create -n perception python=3.10
conda activate perception
pip install -r requirements.txt
```

## Dataset Directory
- ground-truth-coco
  - annotations.json
- Predictions
  - 09282023170518_top_image.png
    - masks.npy
    - outputs.json
  - ...

## Run Inference (Question Answering)
```bash
python3 eval.py --threshold 20000 # compute area-based confusion matrix and performance metrics when pixel area threshold is 20000
```

## Walk-thru
Please refer to the Jupyter notebook (perception.ipynb) for more thorough walk-through of my work.

---

# Algorithm
## Dataset
The dataset consists of ground truth (GT) annotations and prediction masks. 
- There are two classes: Box and Wall.
- The GT annotations contain exterior vertices of instance segmentation of objects of interest in each of 10 unique images.
- The prediction masks contain exterior and interior pixels of instance segmentation of objects of interest in each of 10 unique images.
- The prediction outputs contain predicted bounding boxes (upper and lower corner vertices), scores, predicted classes, and image file names.

## Area-based Mapping & Confusion Matrix
In the dataset, the ground truth annotations and prediction annotations are NOT 1-to-1 mapped.
In other words, we do not know which ground truth label corresponds with which prediction label.
Thus, it is not feasible to compute a confusion matrix based on classification accuracy.
Furthermore, this is a binary classification task (box or wall) with there are only 16 walls in the ground truth labels.
Therefore, as a tweak, I compute a pixel-area based confusion matrix. The steps are as followings:
1. Compute pixel-based True Positive (TP). This is done by finding the intersected areas.
2. Compute pixel-baded False Positive (FP). This is done by finding the predicted areas subtracted by intersected areas.
3. Compute pixel-based False Negative (FN). This is done by finding all the ground truth areas subtracted by intersected areas.
4. Compute Intersection over Union (IoU). The formula is (TP) / (TP + FP + FN).
5. Set True Negative (TN) to 0 as there is no such a case where prediction and ground truth masks are both none (no mask).
6. Repeat steps 1 to 5 for each predicted mask agains all the ground truth masks within the same image.
7. Per image, find an index when the IoU is the highest.
8. Using the indices, compute pixel-based True Positive (TP). This is done by adding up the intersected areas among all the images.
9. Using the indices, compute pixel-baded False Positive (FP). This is done by adding up the predicted areas subtracted by intersected areas among all the images.
10. Using the indices, compute pixel-based False Negative (FN). This is done by adding up the ground truth areas subtracted by intersected areas among all the images.

## Recall, Precision, F1 Socre, & Accuracy
Using TP, FP, and FN, we can calculate recall, precision, f1 score, and accuracy.
- recall = TP / (TP + FN)
- precision = TP / (TP + FP)
- f1 score = 2 * recall * precision / (recall + precision)
- accuracy = (TP + TN) / (TP + FP + TN + FN)
